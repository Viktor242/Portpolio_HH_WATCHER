#!/usr/bin/env python3
"""
–ü—Ä–æ—Å—Ç–æ–π –≤–µ–±-–ø–∞—Ä—Å–µ—Ä –¥–ª—è hh.ru –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
–ò—Å–ø–æ–ª—å–∑—É–µ—Ç —Ç–æ–ª—å–∫–æ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ Python
"""

import urllib.request
import urllib.parse
import json
import csv
import re
import gzip
from datetime import datetime
from pathlib import Path
import time
import random

def get_random_headers():
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–ª—É—á–∞–π–Ω—ã—Ö –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ –¥–ª—è –æ–±—Ö–æ–¥–∞ –±–ª–æ–∫–∏—Ä–æ–≤–æ–∫"""
    user_agents = [
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36",
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:109.0) Gecko/20100101 Firefox/121.0",
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Edge/120.0.0.0 Safari/537.36"
    ]
    
    return {
        "User-Agent": random.choice(user_agents),
        "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8",
        "Accept-Language": "ru-RU,ru;q=0.9,en;q=0.8",
        "Accept-Encoding": "gzip, deflate, br",
        "Connection": "keep-alive",
        "Upgrade-Insecure-Requests": "1",
        "DNT": "1",
        "Referer": "https://hh.ru/"
    }

def search_vacancies_api(query: str, area: str = "22") -> list:
    """–ü–æ–∏—Å–∫ –≤–∞–∫–∞–Ω—Å–∏–π —á–µ—Ä–µ–∑ API hh.ru"""
    
    print(f"üîç API –ø–æ–∏—Å–∫: {query}")
    
    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∑–∞–ø—Ä–æ—Å–∞
    params = {
        "text": query,
        "area": area,  # 22 = –í–ª–∞–¥–∏–≤–æ—Å—Ç–æ–∫
        "per_page": 50,
        "page": 0
    }
    
    # –§–æ—Ä–º–∏—Ä—É–µ–º URL
    base_url = "https://api.hh.ru/vacancies"
    query_string = urllib.parse.urlencode(params)
    url = f"{base_url}?{query_string}"
    
    try:
        # –°–æ–∑–¥–∞–µ–º –∑–∞–ø—Ä–æ—Å
        request = urllib.request.Request(url, headers=get_random_headers())
        
        # –í—ã–ø–æ–ª–Ω—è–µ–º –∑–∞–ø—Ä–æ—Å
        with urllib.request.urlopen(request, timeout=30) as response:
            if response.status == 200:
                # –ß–∏—Ç–∞–µ–º –¥–∞–Ω–Ω—ã–µ
                raw_data = response.read()
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å–∂–∞—Ç—ã –ª–∏ –¥–∞–Ω–Ω—ã–µ gzip
                if response.headers.get('Content-Encoding') == 'gzip':
                    raw_data = gzip.decompress(raw_data)
                
                data = json.loads(raw_data.decode('utf-8'))
                
                vacancies = []
                items = data.get('items', [])
                print(f"  üìä –ù–∞–π–¥–µ–Ω–æ –≤–∞–∫–∞–Ω—Å–∏–π: {len(items)}")
                
                for item in items:
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º –æ—Å–Ω–æ–≤–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
                    title = item.get('name', '')
                    company = item.get('employer', {}).get('name', '–ù–µ —É–∫–∞–∑–∞–Ω–∞')
                    vacancy_id = item.get('id', '')
                    url = item.get('alternate_url', '')
                    
                    # –ó–∞—Ä–ø–ª–∞—Ç–∞
                    salary = item.get('salary')
                    if salary:
                        salary_from = salary.get('from')
                        salary_to = salary.get('to')
                        currency = salary.get('currency', 'RUR')
                        
                        if salary_from and salary_to:
                            salary_text = f"{salary_from:,}‚Äì{salary_to:,} {currency}"
                        elif salary_from:
                            salary_text = f"–æ—Ç {salary_from:,} {currency}"
                        elif salary_to:
                            salary_text = f"–¥–æ {salary_to:,} {currency}"
                        else:
                            salary_text = "–Ω–µ —É–∫–∞–∑–∞–Ω–æ"
                    else:
                        salary_text = "–Ω–µ —É–∫–∞–∑–∞–Ω–æ"
                    
                    # –î–∞—Ç–∞ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏
                    published_at = item.get('published_at', '')
                    if published_at:
                        try:
                            # –ü–∞—Ä—Å–∏–º ISO –¥–∞—Ç—É
                            pub_datetime = datetime.fromisoformat(published_at.replace('Z', '+00:00'))
                            date_text = pub_datetime.strftime("%Y-%m-%d %H:%M")
                            
                            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—É—é –¥–∞—Ç—É
                            now = datetime.now()
                            diff = now - pub_datetime.replace(tzinfo=None)
                            
                            if diff.days == 0:
                                relative_date = "—Å–µ–≥–æ–¥–Ω—è"
                            elif diff.days == 1:
                                relative_date = "–≤—á–µ—Ä–∞"
                            elif diff.days <= 7:
                                relative_date = f"{diff.days} –¥–Ω–µ–π –Ω–∞–∑–∞–¥"
                            else:
                                relative_date = date_text
                        except:
                            date_text = published_at
                            relative_date = "–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"
                    else:
                        date_text = "–Ω–µ —É–∫–∞–∑–∞–Ω–æ"
                        relative_date = "–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –≤–∞–∫–∞–Ω—Å–∏—è —Å–≤–µ–∂–∞—è (–∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 3 –¥–Ω—è)
                    if not is_recent_vacancy(published_at):
                        continue
                    
                    vacancy_data = {
                        "id": vacancy_id,
                        "–ù–∞–∑–≤–∞–Ω–∏–µ –≤–∞–∫–∞–Ω—Å–∏–∏": title,
                        "–ö–æ–º–ø–∞–Ω–∏—è": company,
                        "–°—Å—ã–ª–∫–∞": url,
                        "–î–∞—Ç–∞ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏": date_text,
                        "–ö–æ–≥–¥–∞": relative_date,
                        "–ó–∞—Ä–ø–ª–∞—Ç–∞": salary_text,
                        "–ó–∞–ø—Ä–æ—Å": query
                    }
                    
                    vacancies.append(vacancy_data)
                    print(f"    üìã {title} - {company} - {salary_text} - {relative_date}")
                
                return vacancies
                
            else:
                print(f"  ‚ùå –û—à–∏–±–∫–∞ HTTP: {response.status}")
                return []
                
    except Exception as e:
        print(f"  ‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞: {e}")
        return []

def is_recent_vacancy(published_at: str) -> bool:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–∞ –ª–∏ –≤–∞–∫–∞–Ω—Å–∏—è –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 3 –¥–Ω—è"""
    if not published_at:
        return False
    
    try:
        # –ü–∞—Ä—Å–∏–º ISO –¥–∞—Ç—É
        pub_datetime = datetime.fromisoformat(published_at.replace('Z', '+00:00'))
        
        # –í—ã—á–∏—Å–ª—è–µ–º —Ä–∞–∑–Ω–∏—Ü—É –≤ –¥–Ω—è—Ö
        now = datetime.now()
        diff = now - pub_datetime.replace(tzinfo=None)
        
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º True –µ—Å–ª–∏ –≤–∞–∫–∞–Ω—Å–∏—è –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–∞ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 3 –¥–Ω—è
        return diff.days <= 3
    except:
        return False

def is_relevant_vacancy(title: str) -> bool:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –æ—Ç–Ω–æ—Å–∏—Ç—Å—è –ª–∏ –≤–∞–∫–∞–Ω—Å–∏—è –∫ –∑–∞–∫—É–ø–∫–∞–º, —Å–Ω–∞–±–∂–µ–Ω–∏—é –∏–ª–∏ –ø—Ä–æ–µ–∫—Ç–∞–º"""
    if not title:
        return False
        
    title_lower = title.lower()
    
    # –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è –∑–∞–∫—É–ø–æ–∫
    procurement_keywords = [
        "–∑–∞–∫—É–ø", "–∑–∞–∫—É–ø–∫", "–∑–∞–∫—É–ø–æ—á–Ω", "–∑–∞–∫—É–ø—â–∏–∫", "procurement"
    ]
    
    # –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è —Å–Ω–∞–±–∂–µ–Ω–∏—è
    supply_keywords = [
        "—Å–Ω–∞–±–∂–µ–Ω", "—Å–Ω–∞–±–∂–µ–Ω–∏", "—Å–Ω–∞–±–∂–µ–Ω—á–µ—Å–∫", "supply"
    ]
    
    # –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è –ø—Ä–æ–µ–∫—Ç–æ–≤
    project_keywords = [
        "–ø—Ä–æ–µ–∫—Ç", "project", "–º–µ–Ω–µ–¥–∂–µ—Ä –ø—Ä–æ–µ–∫—Ç", "—Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å –ø—Ä–æ–µ–∫—Ç", 
        "–∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–æ—Ä –ø—Ä–æ–µ–∫—Ç", "—É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç"
    ]
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
    has_procurement = any(keyword in title_lower for keyword in procurement_keywords)
    has_supply = any(keyword in title_lower for keyword in supply_keywords)
    has_project = any(keyword in title_lower for keyword in project_keywords)
    
    return has_procurement or has_supply or has_project

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print("üåê –ü–†–û–°–¢–û–ô –í–ï–ë-–ü–ê–†–°–ï–† HH.RU")
    print("üìÖ –§–ò–õ–¨–¢–†: –¢–û–õ–¨–ö–û –í–ê–ö–ê–ù–°–ò–ò –ó–ê –ü–û–°–õ–ï–î–ù–ò–ï 3 –î–ù–Ø")
    print("=" * 60)
    
    # –ó–∞–ø—Ä–æ—Å—ã –¥–ª—è –ø–æ–∏—Å–∫–∞
    queries = [
        # –ó–∞–∫—É–ø–∫–∏ –∏ —Å–Ω–∞–±–∂–µ–Ω–∏–µ
        "–º–µ–Ω–µ–¥–∂–µ—Ä –ø–æ –∑–∞–∫—É–ø–∫–∞–º",
        "–º–µ–Ω–µ–¥–∂–µ—Ä –ø–æ –∑–∞–∫—É–ø—É", 
        "–º–µ–Ω–µ–¥–∂–µ—Ä –ø–æ –∑–∞–∫—É–ø–∫–∞–º –∏ —Å–Ω–∞–±–∂–µ–Ω–∏—é",
        "—Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç –ø–æ –∑–∞–∫—É–ø–∫–∞–º",
        "–∑–∞–∫—É–ø—â–∏–∫",
        "–º–µ–Ω–µ–¥–∂–µ—Ä –ø–æ —Å–Ω–∞–±–∂–µ–Ω–∏—é",
        "—Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç –ø–æ —Å–Ω–∞–±–∂–µ–Ω–∏—é",
        
        # –ü—Ä–æ–µ–∫—Ç—ã
        "–º–µ–Ω–µ–¥–∂–µ—Ä –ø—Ä–æ–µ–∫—Ç–æ–≤",
        "—Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å –ø—Ä–æ–µ–∫—Ç–æ–≤",
        "project manager"
    ]
    
    all_vacancies = []
    
    for i, query in enumerate(queries, 1):
        print(f"\nüìã {i}/{len(queries)}: {query}")
        vacancies = search_vacancies_api(query)
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –≤–∞–∫–∞–Ω—Å–∏–∏
        relevant_vacancies = [v for v in vacancies if is_relevant_vacancy(v['–ù–∞–∑–≤–∞–Ω–∏–µ –≤–∞–∫–∞–Ω—Å–∏–∏'])]
        print(f"  ‚úÖ –†–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö: {len(relevant_vacancies)}")
        
        all_vacancies.extend(relevant_vacancies)
        
        # –ü–∞—É–∑–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
        sleep_time = random.uniform(2, 4)
        print(f"  ‚è≥ –ü–∞—É–∑–∞: {sleep_time:.1f} —Å–µ–∫")
        time.sleep(sleep_time)
    
    # –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è –ø–æ ID
    unique_vacancies = {}
    for vacancy in all_vacancies:
        vacancy_id = vacancy.get("id", "")
        if vacancy_id and vacancy_id not in unique_vacancies:
            unique_vacancies[vacancy_id] = vacancy
        elif not vacancy_id:
            # –ï—Å–ª–∏ –Ω–µ—Ç ID, –∏—Å–ø–æ–ª—å–∑—É–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ + –∫–æ–º–ø–∞–Ω–∏—è
            key = f"{vacancy['–ù–∞–∑–≤–∞–Ω–∏–µ –≤–∞–∫–∞–Ω—Å–∏–∏']}_{vacancy['–ö–æ–º–ø–∞–Ω–∏—è']}"
            if key not in unique_vacancies:
                unique_vacancies[key] = vacancy
    
    final_vacancies = list(unique_vacancies.values())
    
    print(f"\nüéØ –ò–¢–û–ì–û: {len(final_vacancies)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –≤–∞–∫–∞–Ω—Å–∏–π")
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ CSV
    if final_vacancies:
        date_str = datetime.now().strftime("%Y-%m-%d")
        output_dir = Path("data") / date_str
        output_dir.mkdir(parents=True, exist_ok=True)
        
        csv_file = output_dir / f"–ó–∞–∫—É–ø–∫–∏_–°–Ω–∞–±–∂–µ–Ω–∏–µ_–ü—Ä–æ–µ–∫—Ç—ã_3–¥–Ω—è_{date_str}.csv"
        
        with csv_file.open("w", newline="", encoding="utf-8-sig") as f:
            writer = csv.writer(f, delimiter=";")
            
            # –ó–∞–≥–æ–ª–æ–≤–∫–∏
            headers = ["–ù–∞–∑–≤–∞–Ω–∏–µ –≤–∞–∫–∞–Ω—Å–∏–∏", "–ö–æ–º–ø–∞–Ω–∏—è", "–°—Å—ã–ª–∫–∞", "–î–∞—Ç–∞ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏", "–ö–æ–≥–¥–∞", "–ó–∞—Ä–ø–ª–∞—Ç–∞", "–ó–∞–ø—Ä–æ—Å"]
            writer.writerow(headers)
            
            # –î–∞–Ω–Ω—ã–µ
            for vacancy in final_vacancies:
                row = [
                    vacancy.get("–ù–∞–∑–≤–∞–Ω–∏–µ –≤–∞–∫–∞–Ω—Å–∏–∏", ""),
                    vacancy.get("–ö–æ–º–ø–∞–Ω–∏—è", ""),
                    vacancy.get("–°—Å—ã–ª–∫–∞", ""),
                    vacancy.get("–î–∞—Ç–∞ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏", ""),
                    vacancy.get("–ö–æ–≥–¥–∞", ""),
                    vacancy.get("–ó–∞—Ä–ø–ª–∞—Ç–∞", ""),
                    vacancy.get("–ó–∞–ø—Ä–æ—Å", "")
                ]
                writer.writerow(row)
        
        print(f"‚úÖ CSV —Ñ–∞–π–ª —Å–æ–∑–¥–∞–Ω: {csv_file}")
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        with_salary = sum(1 for v in final_vacancies if v['–ó–∞—Ä–ø–ª–∞—Ç–∞'] != "–Ω–µ —É–∫–∞–∑–∞–Ω–æ")
        with_date = sum(1 for v in final_vacancies if v['–î–∞—Ç–∞ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏'] != "–Ω–µ —É–∫–∞–∑–∞–Ω–æ")
        companies = len(set(v['–ö–æ–º–ø–∞–Ω–∏—è'] for v in final_vacancies))
        
        print(f"\nüìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
        print(f"  ‚Ä¢ –í—Å–µ–≥–æ –≤–∞–∫–∞–Ω—Å–∏–π: {len(final_vacancies)}")
        print(f"  ‚Ä¢ –ö–æ–º–ø–∞–Ω–∏–π: {companies}")
        print(f"  ‚Ä¢ –° –∑–∞—Ä–ø–ª–∞—Ç–æ–π: {with_salary}")
        print(f"  ‚Ä¢ –° –¥–∞—Ç–æ–π: {with_date}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ "–î–∏–∫–∏–π –£–ª–æ–≤"
        wild_catch = [v for v in final_vacancies if "–¥–∏–∫–∏–π —É–ª–æ–≤" in v['–ö–æ–º–ø–∞–Ω–∏—è'].lower()]
        if wild_catch:
            print(f"  üéØ –ù–ê–ô–î–ï–ù–ê '–î–∏–∫–∏–π –£–ª–æ–≤': {len(wild_catch)} –≤–∞–∫–∞–Ω—Å–∏–π")
            for v in wild_catch:
                print(f"    - {v['–ù–∞–∑–≤–∞–Ω–∏–µ –≤–∞–∫–∞–Ω—Å–∏–∏']} - {v['–ó–∞—Ä–ø–ª–∞—Ç–∞']} ({v['–ö–æ–≥–¥–∞']})")
        else:
            print(f"  ‚ùå '–î–∏–∫–∏–π –£–ª–æ–≤' –Ω–µ –Ω–∞–π–¥–µ–Ω")
        
        # –¢–æ–ø-5 –∫–æ–º–ø–∞–Ω–∏–π
        company_counts = {}
        for vacancy in final_vacancies:
            company = vacancy['–ö–æ–º–ø–∞–Ω–∏—è']
            company_counts[company] = company_counts.get(company, 0) + 1
        
        top_companies = sorted(company_counts.items(), key=lambda x: x[1], reverse=True)[:5]
        print(f"\nüè¢ –¢–æ–ø-5 –∫–æ–º–ø–∞–Ω–∏–π:")
        for company, count in top_companies:
            print(f"  ‚Ä¢ {company}: {count} –≤–∞–∫–∞–Ω—Å–∏–π")
    
    else:
        print("‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è")

if __name__ == "__main__":
    main()
