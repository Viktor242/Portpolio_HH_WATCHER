#!/usr/bin/env python3
"""
–ü–∞—Ä—Å–µ—Ä –≤–∞–∫–∞–Ω—Å–∏–π –ø–æ –ø—Ä–æ–¥–∞–∂–∞–º –∏ –∫–æ–º–º–µ—Ä—Ü–∏–∏
"""

import urllib.request
import urllib.parse
import json
import csv
import re
import gzip
from datetime import datetime
from pathlib import Path
import time
import random

def get_random_headers():
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–ª—É—á–∞–π–Ω—ã—Ö –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ –¥–ª—è –æ–±—Ö–æ–¥–∞ –±–ª–æ–∫–∏—Ä–æ–≤–æ–∫"""
    user_agents = [
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36",
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:109.0) Gecko/20100101 Firefox/121.0",
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Edge/120.0.0.0 Safari/537.36"
    ]
    
    return {
        "User-Agent": random.choice(user_agents),
        "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8",
        "Accept-Language": "ru-RU,ru;q=0.9,en;q=0.8",
        "Accept-Encoding": "gzip, deflate, br",
        "Connection": "keep-alive",
        "Upgrade-Insecure-Requests": "1",
        "DNT": "1",
        "Referer": "https://hh.ru/"
    }

def is_recent_vacancy(published_at: str) -> bool:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–∞ –ª–∏ –≤–∞–∫–∞–Ω—Å–∏—è –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 3 –¥–Ω—è"""
    if not published_at:
        return False
    
    try:
        # –ü–∞—Ä—Å–∏–º ISO –¥–∞—Ç—É
        pub_datetime = datetime.fromisoformat(published_at.replace('Z', '+00:00'))
        
        # –í—ã—á–∏—Å–ª—è–µ–º —Ä–∞–∑–Ω–∏—Ü—É –≤ –¥–Ω—è—Ö
        now = datetime.now()
        diff = now - pub_datetime.replace(tzinfo=None)
        
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º True –µ—Å–ª–∏ –≤–∞–∫–∞–Ω—Å–∏—è –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–∞ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 3 –¥–Ω—è
        return diff.days <= 3
    except:
        return False

def is_sales_vacancy(title: str) -> bool:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –æ—Ç–Ω–æ—Å–∏—Ç—Å—è –ª–∏ –≤–∞–∫–∞–Ω—Å–∏—è –∫ –ø—Ä–æ–¥–∞–∂–∞–º –∏ –∫–æ–º–º–µ—Ä—Ü–∏–∏"""
    if not title:
        return False
        
    title_lower = title.lower()
    
    # –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è –ø—Ä–æ–¥–∞–∂
    sales_keywords = [
        "–ø—Ä–æ–¥–∞–∂", "–ø—Ä–æ–¥–∞–∂–Ω", "–ø—Ä–æ–¥–∞–∂–Ω–∏–∫", "sales", "–º–µ–Ω–µ–¥–∂–µ—Ä –ø–æ –ø—Ä–æ–¥–∞–∂", 
        "—Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å –ø—Ä–æ–¥–∞–∂", "–¥–∏—Ä–µ–∫—Ç–æ—Ä –ø–æ –ø—Ä–æ–¥–∞–∂", "—Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç –ø–æ –ø—Ä–æ–¥–∞–∂",
        "–æ–ø—Ç–æ–≤", "–æ–ø—Ç–æ–≤—ã–π", "–∫–∞—Ç–µ–≥–æ—Ä–∏–π–Ω", "–∫–∞—Ç–µ–≥–æ—Ä–∏", "–∫–æ–º–º–µ—Ä—á–µ—Å–∫", 
        "—Ä–∞–∑–≤–∏—Ç–∏–µ –±–∏–∑–Ω–µ—Å", "–∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–æ—Ä –ø—Ä–æ–¥–∞–∂", "–∞–Ω–∞–ª–∏—Ç–∏–∫ –ø—Ä–æ–¥–∞–∂",
        "—Ä–∞–±–æ—Ç–∞ —Å –∫–ª–∏–µ–Ω—Ç", "–∫–ª—é—á–µ–≤—ã–µ –∫–ª–∏–µ–Ω—Ç", "key account", "–∞–∫—Ç–∏–≤–Ω—ã–µ –ø—Ä–æ–¥–∞–∂",
        "b2b", "–∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω", "–∏–Ω—Ç–µ—Ä–Ω–µ—Ç –ø—Ä–æ–¥–∞–∂", "–æ–Ω–ª–∞–π–Ω –ø—Ä–æ–¥–∞–∂", "e-commerce",
        "—Ç–æ—Ä–≥–æ–≤—ã–π –ø—Ä–µ–¥—Å—Ç–∞–≤–∏—Ç–µ–ª—å", "—Å—É–ø–µ—Ä–≤–∞–π–∑–µ—Ä", "—Ä–µ–≥–∏–æ–Ω–∞–ª—å–Ω—ã–π –º–µ–Ω–µ–¥–∂–µ—Ä",
        "—Ç–µ—Ä—Ä–∏—Ç–æ—Ä–∏–∞–ª—å–Ω—ã–π –º–µ–Ω–µ–¥–∂–µ—Ä", "–∫–ª–∏–µ–Ω—Ç—Å–∫–∏–π –º–µ–Ω–µ–¥–∂–µ—Ä", "–∞–∫–∫–∞—É–Ω—Ç –º–µ–Ω–µ–¥–∂–µ—Ä"
    ]
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
    return any(keyword in title_lower for keyword in sales_keywords)

def search_vacancies_api(query: str, area: str = "22") -> list:
    """–ü–æ–∏—Å–∫ –≤–∞–∫–∞–Ω—Å–∏–π —á–µ—Ä–µ–∑ API hh.ru"""
    
    print(f"üîç API –ø–æ–∏—Å–∫: {query}")
    
    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∑–∞–ø—Ä–æ—Å–∞
    params = {
        "text": query,
        "area": area,  # 22 = –í–ª–∞–¥–∏–≤–æ—Å—Ç–æ–∫
        "per_page": 50,
        "page": 0
    }
    
    # –§–æ—Ä–º–∏—Ä—É–µ–º URL
    base_url = "https://api.hh.ru/vacancies"
    query_string = urllib.parse.urlencode(params)
    url = f"{base_url}?{query_string}"
    
    try:
        # –°–æ–∑–¥–∞–µ–º –∑–∞–ø—Ä–æ—Å
        request = urllib.request.Request(url, headers=get_random_headers())
        
        # –í—ã–ø–æ–ª–Ω—è–µ–º –∑–∞–ø—Ä–æ—Å
        with urllib.request.urlopen(request, timeout=30) as response:
            if response.status == 200:
                # –ß–∏—Ç–∞–µ–º –¥–∞–Ω–Ω—ã–µ
                raw_data = response.read()
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å–∂–∞—Ç—ã –ª–∏ –¥–∞–Ω–Ω—ã–µ gzip
                if response.headers.get('Content-Encoding') == 'gzip':
                    raw_data = gzip.decompress(raw_data)
                
                data = json.loads(raw_data.decode('utf-8'))
                
                vacancies = []
                items = data.get('items', [])
                print(f"  üìä –ù–∞–π–¥–µ–Ω–æ –≤–∞–∫–∞–Ω—Å–∏–π: {len(items)}")
                
                for item in items:
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º –æ—Å–Ω–æ–≤–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
                    title = item.get('name', '')
                    company = item.get('employer', {}).get('name', '–ù–µ —É–∫–∞–∑–∞–Ω–∞')
                    vacancy_id = item.get('id', '')
                    url = item.get('alternate_url', '')
                    published_at = item.get('published_at', '')
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –≤–∞–∫–∞–Ω—Å–∏—è —Å–≤–µ–∂–∞—è (–∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 3 –¥–Ω—è)
                    if not is_recent_vacancy(published_at):
                        continue
                    
                    # –ó–∞—Ä–ø–ª–∞—Ç–∞
                    salary = item.get('salary')
                    if salary:
                        salary_from = salary.get('from')
                        salary_to = salary.get('to')
                        currency = salary.get('currency', 'RUR')
                        
                        if salary_from and salary_to:
                            salary_text = f"{salary_from:,}‚Äì{salary_to:,} {currency}"
                        elif salary_from:
                            salary_text = f"–æ—Ç {salary_from:,} {currency}"
                        elif salary_to:
                            salary_text = f"–¥–æ {salary_to:,} {currency}"
                        else:
                            salary_text = "–Ω–µ —É–∫–∞–∑–∞–Ω–æ"
                    else:
                        salary_text = "–Ω–µ —É–∫–∞–∑–∞–Ω–æ"
                    
                    # –î–∞—Ç–∞ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏
                    if published_at:
                        try:
                            # –ü–∞—Ä—Å–∏–º ISO –¥–∞—Ç—É
                            pub_datetime = datetime.fromisoformat(published_at.replace('Z', '+00:00'))
                            date_text = pub_datetime.strftime("%Y-%m-%d %H:%M")
                            
                            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—É—é –¥–∞—Ç—É
                            now = datetime.now()
                            diff = now - pub_datetime.replace(tzinfo=None)
                            
                            if diff.days == 0:
                                relative_date = "—Å–µ–≥–æ–¥–Ω—è"
                            elif diff.days == 1:
                                relative_date = "–≤—á–µ—Ä–∞"
                            elif diff.days <= 7:
                                relative_date = f"{diff.days} –¥–Ω–µ–π –Ω–∞–∑–∞–¥"
                            else:
                                relative_date = date_text
                        except:
                            date_text = published_at
                            relative_date = "–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"
                    else:
                        date_text = "–Ω–µ —É–∫–∞–∑–∞–Ω–æ"
                        relative_date = "–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"
                    
                    vacancy_data = {
                        "id": vacancy_id,
                        "–ù–∞–∑–≤–∞–Ω–∏–µ –≤–∞–∫–∞–Ω—Å–∏–∏": title,
                        "–ö–æ–º–ø–∞–Ω–∏—è": company,
                        "–°—Å—ã–ª–∫–∞": url,
                        "–î–∞—Ç–∞ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏": date_text,
                        "–ö–æ–≥–¥–∞": relative_date,
                        "–ó–∞—Ä–ø–ª–∞—Ç–∞": salary_text,
                        "–ó–∞–ø—Ä–æ—Å": query
                    }
                    
                    vacancies.append(vacancy_data)
                    print(f"    üìã {title} - {company} - {salary_text} - {relative_date}")
                
                return vacancies
                
            else:
                print(f"  ‚ùå –û—à–∏–±–∫–∞ HTTP: {response.status}")
                return []
                
    except Exception as e:
        print(f"  ‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞: {e}")
        return []

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print("üõí –ü–ê–†–°–ï–† –í–ê–ö–ê–ù–°–ò–ô –ü–û –ü–†–û–î–ê–ñ–ê–ú –ò –ö–û–ú–ú–ï–†–¶–ò–ò")
    print("üìÖ –§–ò–õ–¨–¢–†: –¢–û–õ–¨–ö–û –í–ê–ö–ê–ù–°–ò–ò –ó–ê –ü–û–°–õ–ï–î–ù–ò–ï 3 –î–ù–Ø")
    print("=" * 70)
    
    # –ó–∞–ø—Ä–æ—Å—ã –¥–ª—è –ø–æ–∏—Å–∫–∞ –ø—Ä–æ–¥–∞–∂ –∏ –∫–æ–º–º–µ—Ä—Ü–∏–∏
    queries = [
        # –û—Å–Ω–æ–≤–Ω—ã–µ –ø—Ä–æ–¥–∞–∂–∏
        "–º–µ–Ω–µ–¥–∂–µ—Ä –ø–æ –ø—Ä–æ–¥–∞–∂–∞–º",
        "—Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å –æ—Ç–¥–µ–ª–∞ –ø—Ä–æ–¥–∞–∂",
        "–¥–∏—Ä–µ–∫—Ç–æ—Ä –ø–æ –ø—Ä–æ–¥–∞–∂–∞–º",
        "—Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç –ø–æ –ø—Ä–æ–¥–∞–∂–∞–º",
        
        # –û–ø—Ç–æ–≤—ã–µ –ø—Ä–æ–¥–∞–∂–∏
        "–æ–ø—Ç–æ–≤—ã–π –º–µ–Ω–µ–¥–∂–µ—Ä",
        "–º–µ–Ω–µ–¥–∂–µ—Ä –æ–ø—Ç–æ–≤—ã—Ö –ø—Ä–æ–¥–∞–∂",
        "—Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å –æ–ø—Ç–æ–≤—ã—Ö –ø—Ä–æ–¥–∞–∂",
        "—Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç –ø–æ –æ–ø—Ç–æ–≤—ã–º –ø—Ä–æ–¥–∞–∂–∞–º",
        
        # –ö–∞—Ç–µ–≥–æ—Ä–∏–π–Ω—ã–π –º–µ–Ω–µ–¥–∂–º–µ–Ω—Ç
        "–∫–∞—Ç–µ–≥–æ—Ä–∏–π–Ω—ã–π –º–µ–Ω–µ–¥–∂–µ—Ä",
        "–º–µ–Ω–µ–¥–∂–µ—Ä –∫–∞—Ç–µ–≥–æ—Ä–∏–∏",
        "—Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å –∫–∞—Ç–µ–≥–æ—Ä–∏–∏",
        
        # –ö–æ–º–º–µ—Ä—Ü–∏—è
        "–∫–æ–º–º–µ—Ä—á–µ—Å–∫–∏–π –¥–∏—Ä–µ–∫—Ç–æ—Ä",
        "–∑–∞–º–µ—Å—Ç–∏—Ç–µ–ª—å –∫–æ–º–º–µ—Ä—á–µ—Å–∫–æ–≥–æ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∞",
        "–º–µ–Ω–µ–¥–∂–µ—Ä –ø–æ —Ä–∞–∑–≤–∏—Ç–∏—é –±–∏–∑–Ω–µ—Å–∞",
        "—Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç –ø–æ —Ä–∞–∑–≤–∏—Ç–∏—é –±–∏–∑–Ω–µ—Å–∞",
        
        # –ö–æ–æ—Ä–¥–∏–Ω–∞—Ü–∏—è –∏ –∞–Ω–∞–ª–∏–∑
        "–∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–æ—Ä –ø—Ä–æ–¥–∞–∂",
        "–∞–Ω–∞–ª–∏—Ç–∏–∫ –ø—Ä–æ–¥–∞–∂",
        
        # –†–∞–±–æ—Ç–∞ —Å –∫–ª–∏–µ–Ω—Ç–∞–º–∏
        "–º–µ–Ω–µ–¥–∂–µ—Ä –ø–æ —Ä–∞–±–æ—Ç–µ —Å –∫–ª–∏–µ–Ω—Ç–∞–º–∏",
        "—Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç –ø–æ —Ä–∞–±–æ—Ç–µ —Å –∫–ª–∏–µ–Ω—Ç–∞–º–∏",
        "–º–µ–Ω–µ–¥–∂–µ—Ä –ø–æ –∫–ª—é—á–µ–≤—ã–º –∫–ª–∏–µ–Ω—Ç–∞–º",
        "key account manager",
        
        # –ê–∫—Ç–∏–≤–Ω—ã–µ –ø—Ä–æ–¥–∞–∂–∏
        "–º–µ–Ω–µ–¥–∂–µ—Ä –∞–∫—Ç–∏–≤–Ω—ã—Ö –ø—Ä–æ–¥–∞–∂",
        "—Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç –ø–æ –∞–∫—Ç–∏–≤–Ω—ã–º –ø—Ä–æ–¥–∞–∂–∞–º",
        
        # B2B –ø—Ä–æ–¥–∞–∂–∏
        "b2b –º–µ–Ω–µ–¥–∂–µ—Ä",
        "–º–µ–Ω–µ–¥–∂–µ—Ä b2b –ø—Ä–æ–¥–∞–∂",
        "–∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω—ã–µ –ø—Ä–æ–¥–∞–∂–∏",
        "–º–µ–Ω–µ–¥–∂–µ—Ä –ø–æ –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω—ã–º –ø—Ä–æ–¥–∞–∂–∞–º",
        
        # –ò–Ω—Ç–µ—Ä–Ω–µ—Ç –ø—Ä–æ–¥–∞–∂–∏
        "–∏–Ω—Ç–µ—Ä–Ω–µ—Ç –ø—Ä–æ–¥–∞–∂–∏",
        "–º–µ–Ω–µ–¥–∂–µ—Ä –∏–Ω—Ç–µ—Ä–Ω–µ—Ç –ø—Ä–æ–¥–∞–∂",
        "–æ–Ω–ª–∞–π–Ω –ø—Ä–æ–¥–∞–∂–∏",
        "e-commerce –º–µ–Ω–µ–¥–∂–µ—Ä",
        
        # –¢–æ—Ä–≥–æ–≤—ã–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–∏—Ç–µ–ª–∏
        "—Ç–æ—Ä–≥–æ–≤—ã–π –ø—Ä–µ–¥—Å—Ç–∞–≤–∏—Ç–µ–ª—å",
        "—Å—É–ø–µ—Ä–≤–∞–π–∑–µ—Ä",
        "—Ä–µ–≥–∏–æ–Ω–∞–ª—å–Ω—ã–π –º–µ–Ω–µ–¥–∂–µ—Ä",
        "—Ç–µ—Ä—Ä–∏—Ç–æ—Ä–∏–∞–ª—å–Ω—ã–π –º–µ–Ω–µ–¥–∂–µ—Ä"
    ]
    
    all_vacancies = []
    
    for i, query in enumerate(queries, 1):
        print(f"\nüìã {i}/{len(queries)}: {query}")
        vacancies = search_vacancies_api(query)
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –≤–∞–∫–∞–Ω—Å–∏–∏ –ø–æ –ø—Ä–æ–¥–∞–∂–∞–º
        relevant_vacancies = [v for v in vacancies if is_sales_vacancy(v['–ù–∞–∑–≤–∞–Ω–∏–µ –≤–∞–∫–∞–Ω—Å–∏–∏'])]
        print(f"  ‚úÖ –†–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö: {len(relevant_vacancies)}")
        
        all_vacancies.extend(relevant_vacancies)
        
        # –ü–∞—É–∑–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
        sleep_time = random.uniform(2, 4)
        print(f"  ‚è≥ –ü–∞—É–∑–∞: {sleep_time:.1f} —Å–µ–∫")
        time.sleep(sleep_time)
    
    # –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è –ø–æ ID
    unique_vacancies = {}
    for vacancy in all_vacancies:
        vacancy_id = vacancy.get("id", "")
        if vacancy_id and vacancy_id not in unique_vacancies:
            unique_vacancies[vacancy_id] = vacancy
        elif not vacancy_id:
            # –ï—Å–ª–∏ –Ω–µ—Ç ID, –∏—Å–ø–æ–ª—å–∑—É–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ + –∫–æ–º–ø–∞–Ω–∏—è
            key = f"{vacancy['–ù–∞–∑–≤–∞–Ω–∏–µ –≤–∞–∫–∞–Ω—Å–∏–∏']}_{vacancy['–ö–æ–º–ø–∞–Ω–∏—è']}"
            if key not in unique_vacancies:
                unique_vacancies[key] = vacancy
    
    final_vacancies = list(unique_vacancies.values())
    
    print(f"\nüéØ –ò–¢–û–ì–û: {len(final_vacancies)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –≤–∞–∫–∞–Ω—Å–∏–π –ø–æ –ø—Ä–æ–¥–∞–∂–∞–º")
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ CSV
    if final_vacancies:
        date_str = datetime.now().strftime("%Y-%m-%d")
        output_dir = Path("data") / date_str
        output_dir.mkdir(parents=True, exist_ok=True)
        
        csv_file = output_dir / f"–ü—Ä–æ–¥–∞–∂–∏_–ö–æ–º–º–µ—Ä—Ü–∏—è_3–¥–Ω—è_{date_str}.csv"
        
        with csv_file.open("w", newline="", encoding="utf-8-sig") as f:
            writer = csv.writer(f, delimiter=";")
            
            # –ó–∞–≥–æ–ª–æ–≤–∫–∏
            headers = ["–ù–∞–∑–≤–∞–Ω–∏–µ –≤–∞–∫–∞–Ω—Å–∏–∏", "–ö–æ–º–ø–∞–Ω–∏—è", "–°—Å—ã–ª–∫–∞", "–î–∞—Ç–∞ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏", "–ö–æ–≥–¥–∞", "–ó–∞—Ä–ø–ª–∞—Ç–∞", "–ó–∞–ø—Ä–æ—Å"]
            writer.writerow(headers)
            
            # –î–∞–Ω–Ω—ã–µ
            for vacancy in final_vacancies:
                row = [
                    vacancy.get("–ù–∞–∑–≤–∞–Ω–∏–µ –≤–∞–∫–∞–Ω—Å–∏–∏", ""),
                    vacancy.get("–ö–æ–º–ø–∞–Ω–∏—è", ""),
                    vacancy.get("–°—Å—ã–ª–∫–∞", ""),
                    vacancy.get("–î–∞—Ç–∞ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏", ""),
                    vacancy.get("–ö–æ–≥–¥–∞", ""),
                    vacancy.get("–ó–∞—Ä–ø–ª–∞—Ç–∞", ""),
                    vacancy.get("–ó–∞–ø—Ä–æ—Å", "")
                ]
                writer.writerow(row)
        
        print(f"‚úÖ CSV —Ñ–∞–π–ª —Å–æ–∑–¥–∞–Ω: {csv_file}")
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        with_salary = sum(1 for v in final_vacancies if v['–ó–∞—Ä–ø–ª–∞—Ç–∞'] != "–Ω–µ —É–∫–∞–∑–∞–Ω–æ")
        with_date = sum(1 for v in final_vacancies if v['–î–∞—Ç–∞ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏'] != "–Ω–µ —É–∫–∞–∑–∞–Ω–æ")
        companies = len(set(v['–ö–æ–º–ø–∞–Ω–∏—è'] for v in final_vacancies))
        
        print(f"\nüìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
        print(f"  ‚Ä¢ –í—Å–µ–≥–æ –≤–∞–∫–∞–Ω—Å–∏–π: {len(final_vacancies)}")
        print(f"  ‚Ä¢ –ö–æ–º–ø–∞–Ω–∏–π: {companies}")
        print(f"  ‚Ä¢ –° –∑–∞—Ä–ø–ª–∞—Ç–æ–π: {with_salary}")
        print(f"  ‚Ä¢ –° –¥–∞—Ç–æ–π: {with_date}")
        
        # –¢–æ–ø-5 –∫–æ–º–ø–∞–Ω–∏–π
        company_counts = {}
        for vacancy in final_vacancies:
            company = vacancy['–ö–æ–º–ø–∞–Ω–∏—è']
            company_counts[company] = company_counts.get(company, 0) + 1
        
        top_companies = sorted(company_counts.items(), key=lambda x: x[1], reverse=True)[:5]
        print(f"\nüè¢ –¢–æ–ø-5 –∫–æ–º–ø–∞–Ω–∏–π:")
        for company, count in top_companies:
            print(f"  ‚Ä¢ {company}: {count} –≤–∞–∫–∞–Ω—Å–∏–π")
    
    else:
        print("‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è")

if __name__ == "__main__":
    main()
